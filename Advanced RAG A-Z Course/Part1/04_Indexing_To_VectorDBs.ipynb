{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4658481a-f484-4d44-a742-52504306561a",
      "metadata": {
        "id": "4658481a-f484-4d44-a742-52504306561a"
      },
      "source": [
        "# Rag From Scratch: Indexing\n",
        "\n",
        "![Screenshot 2024-03-25 at 8.23.02 PM.png](indexing.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "095c203b",
      "metadata": {
        "id": "095c203b"
      },
      "source": [
        "## Set Environment Vars and API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96d81ac8",
      "metadata": {
        "id": "96d81ac8"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'advanced-rag'\n",
        "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c574333e-6a0d-4f4e-8897-783cd71bdcc2",
      "metadata": {
        "id": "c574333e-6a0d-4f4e-8897-783cd71bdcc2"
      },
      "source": [
        "## Part 12: Multi-representation Indexing\n",
        "\n",
        "Flow:\n",
        "\n",
        " ![Screenshot 2024-03-16 at 5.54.55 PM.png](multiindexing.png)\n",
        "\n",
        "Docs:\n",
        "\n",
        "https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf368e7-ebf6-4469-bfa7-62466184afbb",
      "metadata": {
        "id": "1bf368e7-ebf6-4469-bfa7-62466184afbb"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = WebBaseLoader(\"https://medium.com/@pankaj_pandey/introduction-to-retrieval-augmented-generation-rag-9209bf8a076d\")\n",
        "docs = loader.load()\n",
        "\n",
        "loader = WebBaseLoader(\"https://medium.com/humansdotai/an-introduction-to-ai-agents-e8c4afd2ee8f\")\n",
        "docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "431c9506-c6c0-463b-af77-9291a63f1d26",
      "metadata": {
        "id": "431c9506-c6c0-463b-af77-9291a63f1d26"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "chain = (\n",
        "    {\"doc\": lambda x: x.page_content}\n",
        "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
        "    | ChatGroq()\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "summaries = chain.batch(docs, {\"max_concurrency\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fb1ce86",
      "metadata": {
        "id": "9fb1ce86",
        "outputId": "f41dff03-42a4-41d2-bb0f-8a28e440fb81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Retrieval-Augmented Generation (RAG) is an AI framework that enhances the accuracy and reliability of Large Language Models (LLMs) by grounding them in external knowledge bases. RAG addresses the inconsistencies and lack of understanding in LLM-generated responses by providing access to up-to-date facts and verifiable sources, increasing user trust. It consists of two phases: retrieval and content generation. In the retrieval phase, relevant information is searched for and retrieved from external knowledge bases, while in the content generation phase, the LLM synthesizes an answer based on both the retrieved information and its internal representation of training data. RAG offers advantages such as access to current and reliable information, reduced opportunities for sensitive data leakage, and lower computational and financial costs in LLM-powered applications. It is implemented in an \"open book\" manner, allowing LLMs to respond to questions by browsing through external content. RAG also helps train LLMs to recognize limitations and teaches them to recognize unanswerable questions. Challenges and ongoing innovations in Retrieval-Augmented Generation include improving both the retrieval and generation ends of the process and optimizing generation techniques for incorporating retrieved information effectively. Python code examples are provided for implementing RAG in various scenarios.',\n",
              " 'AI Agents are intelligent systems that can perform tasks, make decisions, and interact with their environment like humans do. They are powered by machine learning, natural language processing, and other advanced technologies, allowing them to learn from data, adapt to new information, and execute complex functions autonomously. AI Agents exist in various forms, such as chatbots providing customer service and robots used in healthcare and manufacturing. They are designed to understand, analyze, and respond to human input, constantly evolving to enhance their capabilities.\\n\\nAI Agents operate independently and can address customer queries, make fast decisions based on real-time information, and simplify business processes. They perceive their surroundings and execute actions through a range of tools, from rule-based systems to machine learning algorithms. AI Agents are the new face of intelligent automation and can handle vast streams of fresh data in uncertain landscapes.\\n\\nThe emergence of AI Agents represents a step towards Artificial General Intelligence (AGI), where machines will emulate human-like flexibility and proficiency across diverse domains. AI Agents work by initiating a journey toward a goal through engaging with core Language Learning Models, formulating a sequence of tasks, gathering relevant information, and iteratively refining their strategy until their objective is achieved.\\n\\nAI Agents transform businesses by infusing tasks with heightened performance, personalization, scalability, and cost-effectiveness. They can serve as guardians against errors, solvers of intricate puzzles, and creators of new fields of opportunities. In the economy, AI Agents have become indispensable across various business domains, revolutionizing service delivery, supply chains, and marketing strategies.\\n\\nDifferent types of AI Agents include Simple Reflex Agents, Model-Based Reflex Agents, Goal-based Agents, Utility-Based AI Agents, and Learning Agents. Hierarchical AI Agents are organized in tiers, with higher-level agents orchestrating lower-level counterparts. The potential of AI Agents spans across diverse industries, but responsible and beneficial utilization of these Agents is essential for enterprises. Market analysis suggests that 2024 is the year for enterprises to embrace the power of AI Agents.']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc5614c1-121c-4ad5-8609-cc0e4a633ee9",
      "metadata": {
        "id": "dc5614c1-121c-4ad5-8609-cc0e4a633ee9"
      },
      "outputs": [],
      "source": [
        "from langchain.storage import InMemoryByteStore\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "model_name = \"BAAI/bge-small-en\"\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "hf_embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "# The vectorstore to use to index the child chunks\n",
        "vectorstore = Chroma(collection_name=\"summaries\",\n",
        "                     embedding_function=hf_embeddings)\n",
        "\n",
        "# The storage layer for the parent documents\n",
        "store = InMemoryByteStore()\n",
        "id_key = \"doc_id\"\n",
        "\n",
        "# The retriever\n",
        "retriever = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    byte_store=store,\n",
        "    id_key=id_key,\n",
        ")\n",
        "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
        "\n",
        "# Docs linked to summaries\n",
        "summary_docs = [\n",
        "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "    for i, s in enumerate(summaries)\n",
        "]\n",
        "\n",
        "# Add\n",
        "retriever.vectorstore.add_documents(summary_docs)\n",
        "retriever.docstore.mset(list(zip(doc_ids, docs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84b531f8",
      "metadata": {
        "id": "84b531f8",
        "outputId": "44fa141f-332b-41b4-aa74-af5c032bc204"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['cd92fc06-5ff8-453c-af47-d769f679645f',\n",
              " '0fe1d412-c3c2-45c3-9637-57cc9948f0b4']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a849c72",
      "metadata": {
        "id": "8a849c72",
        "outputId": "d2e490e9-68a6-4dc3-c321-5380fe62abdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Introduction to Retrieval-Augmented Generation (RAG) | by Pankaj Pandey | MediumOpen in appSign upSign inWriteSign upSign inMastodonIntroduction to Retrieval-Augmented Generation (RAG)Pankaj Pandey·Follow6 min read·Dec 16, 2023--ListenShareRAG systems aim to address the drawbacks of Large Language Models by incorporating factual information during response generation, mitigating issues such as knowledge cutoff and response hallucination.Retrieval Augmented Generation (RAG)The world is advancing rapidly, introducing new technologies and stacks in AI and other areas every day. Large Language Models (LLMs) are a significant innovation in this space. However, LLMs have drawbacks due to their knowledge cutoff and other reasons, leading to confident but inaccurate responses. The RAG systems aim to address this issue by incorporating factual information during response generation to prevent hallucination and retrieve accurate responses.Introduction:RAG is an AI framework that improves the accuracy and reliability of large language models (LLMs) by grounding them in external knowledge bases.LLMs can be inconsistent and prone to errors, lacking true understanding of word meaning.RAG addresses these issues by providing access to up-to-date facts and verifiable sources, increasing user trust.Purpose of RAG:Grounding LLMs on external knowledge for improved responses.Overcoming inconsistencies in LLM-generated answers.Challenges Addressed by RAG:Inconsistency in LLM responses.Lack of understanding of the meaning of words by LLMs.Reduction of opportunities for the model to leak sensitive data.Benefits of RAG:Accuracy and Fact-Checking:Ensures LLM responses are based on reliable sources, allowing users to verify claims.Reduced Bias and Hallucination:Limits LLM reliance on internal biases and prevents fabrication of information.Lower Cost and Maintenance:Reduces the need for continuous LLM retraining and updates, saving computational resources.How RAG Works:RAG consists of two distinct phases: retrieval and content generation. In the retrieval phase, algorithms search for and retrieve relevant information from external knowledge bases. This information is then used in the generative phase, where the LLM synthesizes an answer based on both the augmented prompt and its internal representation of training data.Phase 1: RetrievalRelevant information is retrieved from external sources based on the user\\'s prompt or question.Sources vary depending on the context (open-domain internet vs. closed-domain enterprise data).Phase 2: Content GenerationThe retrieved information is appended to the user\\'s prompt and fed to the LLM.The LLM generates a personalized answer based on the augmented prompt and its internal knowledge base.The answer can be delivered with links to its sources for transparency.Advantages and Applications of RAGRAG offers several advantages, including access to the latest, reliable facts, reduction in sensitive data leakage and decreased need for continuous model retraining. It finds applications in personalized responses, verifiable answers and lowering computational and financial costs in enterprise settings.Access to current and reliable information.Reduced opportunities for sensitive data leakage.Lower computational and financial costs in LLM-powered applications.Implementation and WorkflowsRAG operates in an “open book” manner, allowing LLMs to respond to questions by browsing through external content. It involves a retrieval phase, where relevant information is gathered and a generative phase, where the LLM synthesizes a response using both external and internal knowledge.Open-Book Approach:Contrasted with closed-book exams, where LLMs rely on memory.Model’s response involves browsing through external content.Workflow:Retrieval phase: Search and gather external information.Generative phase: Synthesize a personalized answer using internal and external knowledge.Teaching LLMs to Recognize LimitationsLLMs, when faced with ambiguous or complex queries, may provide inaccurate responses. RAG helps in training LLMs to recognize unanswerable questions and prompts them to either admit uncertainty or ask clarifying questions.Recognition of Limitations:LLMs prone to making things up in challenging scenarios.Training LLMs to explicitly recognize unanswerable questions.Challenges and Ongoing Innovations in Retrieval-Augmented GenerationWhile RAG is a powerful tool, there are still some challenges persist and ongoing innovations are necessary. Lots of Research is focused on improving both the retrieval and generation ends of the process to enhance the effectiveness of RAG.Challenges:Imperfections in RAG.Enriching prompts with relevant information using vectors.Innovations and Research:Focus on retrieval: Finding and fetching the most relevant information.Focus on generation: Structuring information for richer responses.Example Scenario: Customer Care ChatbotAlice, an employee, asks about taking vacation in half-day increments.The LLM retrieves relevant data from Alice\\'s HR files and company policies.It generates a personalized answer confirming her vacation allowance and half-day eligibility.The answer is delivered with links to the HR files and policies for verification.Challenges and Future DirectionsTraining LLMs to recognize \"unknowns\" and avoid making things up.Improving retrieval algorithms for finding the most relevant information.Optimizing generation techniques for incorporating retrieved information effectively.Python Code Examples:1. Simple Retrieval with Elasticsearch:from elasticsearch import Elasticsearches = Elasticsearch()query = \"early dismissal school Wednesdays\"results = es.search(index=\"documents\", query={\"query\": {\"match\": {\"text\": query}}})# Process results and use them to augment the LLM prompt...2. Combining Retrieval and Generation with Transformers:# Using a transformer-based model with RAG for information retrieval and generationfrom transformers import pipelinerag_qa_pipeline = pipeline(\"question-answering\", model=\"facebook/rag-token-base\", retriever=\"facebook/rag-token-base\")question = \"What is retrieval-augmented generation?\"answer = rag_qa_pipeline(question, truncation=True, return_prompt=True)print(answer)from transformers import AutoTokenizer, AutoModelForSequenceClassificationtokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")model = AutoModelForSequenceClassification.from_pretrained(\"rag/bert-base-uncased-rag\")prompt = \"Alice asks about taking vacation in half-day increments.\"retrieved_info = ...  # Retrieved information from external sourceencoded_prompt = tokenizer(prompt + retrieved_info, return_tensors=\"pt\")output = model(**encoded_prompt)# Process output and use it to generate the LLM response...# Sample Python code demonstrating the retrieval phase in RAGdef retrieval_phase(user_prompt, external_data):    # Algorithm to search and retrieve relevant information    retrieved_info = search_and_retrieve(user_prompt, external_data)    return retrieved_info# Sample Python code demonstrating the generative phase in RAGdef generative_phase(augmented_prompt, internal_data):    # Algorithm to synthesize a personalized answer using internal and external knowledge    answer = generate_response(augmented_prompt, internal_data)    return answer3. RAG Example in a question answering system:# Example of using RAG in a question answering systemfrom transformers import RagTokenizer, RagRetriever, RagSequenceForGenerationtokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-base\")retriever = RagRetriever.from_pretrained(\"facebook/rag-token-base\")model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")# Retrieve relevant informationinput_text = \"What is retrieval-augmented generation?\"retrieved_info = retriever.retrieve(input_text)# Generate response using RAGgenerated_response = model.generate(**retrieved_info)print(tokenizer.decode(generated_response[0], skip_special_tokens=True))4. Personalized and Verifiable Responses with RAGRetrieval-augmented generation (RAG) enables large language models (LLMs) to provide personalized responses without constant retraining. It reduces the need for manual scripting in chatbots, allowing the model to adapt to new information dynamically.# Using RAG to generate personalized responses in a chatbotfrom transformers import RagRetriever, RagSequenceForGenerationretriever = RagRetriever.from_pretrained(\"facebook/rag-token-base\")model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")# User\\'s queryuser_query = \"Can I take vacation in half-day increments?\"# Retrieve relevant informationretrieved_info = retriever.retrieve(user_query)# Generate personalized response using RAGgenerated_response = model.generate(**retrieved_info)print(tokenizer.decode(generated_response[0], skip_special_tokens=True))5. Teaching the Model to Recognize UnknownsLLMs need explicit training to recognize and admit when they cannot answer certain questions. RAG addresses the challenge of ambiguous queries, complex questions and situations where the model lacks information.# Training an LLM to recognize unknown questions using RAGfrom transformers import RagRetriever, RagSequenceForGenerationretriever = RagRetriever.from_pretrained(\"facebook/rag-token-base\")model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")# User\\'s ambiguous queryambiguous_query = \"How much vacation time do I have?\"# Retrieve relevant informationretrieved_info = retriever.retrieve(ambiguous_query)# Train the model to recognize unknowns# ...# Generate response using RAG, considering the unknown recognitiongenerated_response = model.generate(**retrieved_info)print(tokenizer.decode(generated_response[0], skip_special_tokens=True))Note: These are simplified examples to understand the basic concepts, the actual implementation may require more complex code and libraries depending on the specific use case and desired functionalities.Conclusion:RAG is a promising approach for improving LLM accuracy and reliability, offering benefits like factual grounding, reduced bias and lower maintenance costs. While challenges remain in areas like unknown recognition and retrieval optimization, ongoing research is pushing the boundaries of RAG capabilities and paving the way for more trustworthy and informative LLM applications.Supporting Information:Vector databases play a crucial role in RAG by efficiently indexing, storing and retrieving information.Lots of Research emphasizes the imperfections of RAG and the need for ongoing improvements in its implementation.Remember: This is a preliminary analysis. Further research and validation are needed to ensure the accuracy and completeness of the information presented.SourcesData-Science-Pipeline-DetectorRetrieval-augmented-generation-RAGLarge Language ModelsRagMachine LearningData ScienceAI----FollowWritten by Pankaj Pandey262 FollowersExpert in software technologies with proficiency in multiple languages, experienced in Generative AI, NLP, Bigdata, and application development.FollowHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://medium.com/@pankaj_pandey/introduction-to-retrieval-augmented-generation-rag-9209bf8a076d', 'title': 'Introduction to Retrieval-Augmented Generation (RAG) | by Pankaj Pandey | Medium', 'description': 'The world is advancing rapidly, introducing new technologies and stacks in AI and other areas every day. Large Language Models (LLMs) are a significant innovation in this space. However, LLMs have…', 'language': 'en'}),\n",
              " Document(page_content='An Introduction to AI Agents. Artificial Intelligence Agents are the… | by Humans.ai | humansdotai | MediumOpen in appSign upSign inWriteSign upSign inAn Introduction to AI AgentsHumans.ai·FollowPublished inhumansdotai·7 min read·Dec 27, 2023--1ListenShareArtificial Intelligence Agents are the digital newcomers revolutionizing our world. These agents, often called AI bots or virtual assistants, are intelligent systems programmed to perform tasks, make decisions, and interact with their environment just like humans do. Powered by machine learning, natural language processing, and other cutting-edge technologies, AI Agents can learn from data, adapt to new information, and execute complex functions autonomously. They exist in various forms, from chatbots providing customer service to sophisticated robots created for healthcare and manufacturing. AI Agents are designed to understand, analyze, and respond to human input, constantly evolving to enhance their capabilities.In this article, we’ll delve into the world of AI agents, exploring their functionalities, the technology behind their intelligence, their applications across industries, and the ethical considerations that arise as these agents become increasingly integrated into our daily lives.Join us on an amazing journey through the fascinating world of AI agents and their transformative potential!Understanding AI AgentsAI Agents navigate their environments and accomplish goals autonomously, free from human intervention. These savvy programs address customer queries, and make fast decisions based on real-time information, revolutionizing the landscape of customer engagement. Think of them as the pioneers redefining our interactions — they’re simplifying business processes and customer communications with an adaptive finesse that transforms the ordinary into extraordinary.These agents work their magic by perceiving their surroundings and executing actions through a spectrum of tools — from rule-based systems and decision-makers to the benefits of machine learning. As digital decision-makers fueled by past and present inputs, AI Agents pursue optimal outcomes, slowly carving the path to a smarter and more intuitive future.AI Agents are revolutionizing the way we interact with technology. Unlike traditional AI interactions where prompts are necessary for responses, AI agents operate independently, driven by goals rather than specific inputs. They’re autonomous problem solvers, seamlessly adapting to new information and environments, evolving with every task to achieve their objectives optimally.In contrast to standard automation processes rooted in fixed parameters and training data, AI Agents flourish in uncertain landscapes, navigating uncharted territories and handling vast streams of fresh data. They’re the new face of intelligent automation. But AI Agents aren’t just intelligent; they’re adept at using computers. From browsing the internet and managing apps to conducting financial transactions and controlling devices, their capabilities are vast and versatile.More importantly, the emergence of AI Agents signifies a step towards Artificial General Intelligence (AGI), where machines will emulate human-like flexibility and unparalleled proficiency across diverse domains. AI Agents represent a groundbreaking step toward this future, where technology’s potential is unknown.How does an AI Agent work?AI Agents operate similarly to popular AI solutions present on the market, namely they require users to input an objective, after which the AI Agent initiates its journey toward the goal by engaging with the core Language Learning Models that operate in the background to return its first output and showcase its understanding of the task at hand.Next comes the meticulous crafting of a task list. Driven by the defined goal, the AI Agent formulates a sequence of tasks, prioritizing their order of completion. Once satisfied with its plan, it delves into information retrieval.Functioning like an experimented computer user, the Agent navigates the vast domain of the internet to gather relevant information. Some advanced agents collaborate with other AI models, enabling access to specialized tasks like image generation and computer vision functionalities. All the collected data is meticulously managed by the Agent and used to relay information back to the user and refine its strategy for more optimized progress.As each task is completed, the Agent actively seeks feedback, both from external sources and through its internal thought process, to estimate its distance from the ultimate goal. Until its objective is achieved, the agent relentlessly iterates, crafting new tasks and seeking more data and feedback to advance toward its goal.These are the fundamental steps a typical AI Agent follows to fulfill any given goal. Yet, the sequencing of steps may vary depending on the different configurations or objectives the AI agent was designed for.How AI Agents transform businessesAI Agents stand as catalysts, elevating the game for businesses by infusing tasks with heightened performance and supercharged outcomes. These agents take on tasks that either surpass human capabilities or liberate us from those tasks we’d rather not tackle. In business, AI Agents aren’t just tools; they’re game-changers, empowering enterprises to rise beyond limits and build new paths of efficiency, personalization, and cost-effectiveness. Overall, AI Agents serve as guardians against errors, the solvers of intricate puzzles, and the creators of new fields of opportunities.AI Agents Characteristics:✅ Enhanced Efficiency: AI Agents perform tasks with impeccable speed and accuracy, effortlessly surpassing humans. They’re the masters of repetitive tasks, allowing humans to focus their attention on complex problem-solving.✅ Tailored Personalization: AI Agents use data analytics to curate personalized customer solutions and recommendations.✅ Unmatched Scalability: Virtual agents boast adaptability like no other, effortlessly scaling their operations to meet the surge during peak seasons or unexpected demand spikes, empowering businesses with unparalleled flexibility.✅ Always On: These tireless digital agents operate around the clock, offering 24/7 customer service. No overtime, no weekend shifts, just unwavering availability.✅ Reduced Costs: By automating routine tasks, AI Agents are the tool that slashes labor costs for businesses. Moreover, they’re handling numerous customer inquiries simultaneously, reducing the need for additional staff.How AI Agents are revolutionizing the economyAI Agents have become indispensable across various business domains, revolutionizing service delivery, supply chains, and marketing strategies. These multifaceted AI Agents can become the backbone of modern business operations, shaping the future with their unparalleled versatility and transformative capabilities, serving as catalysts for transformative change, with examples transcending multiple industries:• Finance: Autonomous agents redefine trading, risk management, and fraud detection. Hedge funds leverage AI-powered agents to analyze market data and execute trades intelligently.• Energy: In power grids and energy markets, adaptive agents streamline operations, automating power generation and distribution with precision and efficiency.• Transportation: Automobile companies like Tesla utilize AI-based agents to develop self-driving cars. These autonomous agents make decisions based on sensory inputs, optimizing traffic flow and supply chain logistics. AI Agents can also help manage traffic flow and improve logistics and supply chain management.• Healthcare: Autonomous agents revolutionize diagnosis and treatment by analyzing medical records, crafting personalized treatment plans, and optimizing resource allocation.• Customer Service: Virtual assistants and AI-driven chatbots enhance customer service across diverse industries, ensuring seamless interactions.• Gaming: Intelligent agents enrich gaming experiences by creating challenging opponents in simulations, enhancing realism for players.• Smart Homes and Buildings: Agents optimize energy consumption and improve comfort by controlling heating, lighting, and other systems in smart homes and buildings.• Robotics: AI Agents can control robots and automate tasks, driving operational efficiency.• Natural Language Processing: Agents facilitate language translation, question answering, and chatbot communication, bridging gaps in user interactions.• Cybersecurity: AI Agents can bolster security measures by detecting intrusions, analyzing malware, and fortifying network security.• Environmental Monitoring: AI Agents contribute to sustainability efforts by monitoring natural resources, tracking climate changes, and enhancing environmental conservation.• Social Media: Agents analyze social media data, unveiling trends, patterns, and personalized recommendations, enriching user experiences.Categories of AI AgentsAI Agents operate nearly independently, navigating their surroundings, interpreting information, and making decisions based on keen observations. Different types of AI Agents are tailor-made to address specific business challenges within their designated domains.Classifying AI Agents involves discerning the impact of their actions on their perceived intelligence and capacities. By delving into the distinct traits of each agent category, there’s ample potential to elevate their efficiency and yield superior outcomes.Simple Reflex AgentsA simple reflex agent operates within predefined guidelines, reacting solely to immediate circumstances. It’s most effective in stable environments with straightforward actions, where its reactive nature suits the situation. Simple Reflex agents work based on condition-action rules, determining responses based on specific conditions.Model-Based Reflex AgentsA model-based Reflex Agent operates on a current percept and an internal state representing the hidden aspects of the world. It adapts its internal state based on how the world evolves and the impact of its actions on it. Model-based Reflex Agents work based on condition-action rules, which specify the appropriate action to take in a particular situation. Unlike simple reflex agents, they also factor in their internal state during decision-making.Goal-based AgentsGoal-based Agents leverage information from their surroundings to achieve defined objectives. Employing search algorithms, these agents efficiently navigate through their environments to reach their set goals.Also known as rule-based, they follow predefined directives to accomplish tasks and act based on specific conditions. They excel in handling complex tasks, finding their utility in robotics, computer vision, and natural language processing. Unlike their basic counterparts, goal-based agents identify optimal decision-making paths tailored to their desired outcomes or goals.Utility-Based AI AgentsUtility-based Agents aim to maximize utility functions or values. They cherry-pick actions with the highest expected utility, measuring how favorable the outcome is. Due to this design, utility-based Agents excel in navigating complex and uncertain scenarios, adapting flexibly to situations.Learning AgentsAI Learning Agents constantly enhance performance through the power of learning. These software agents start with basic knowledge and refine themselves through machine learning, constantly evolving to achieve better outcomes. AI learning agents observe, learn, and act based on feedback loops, constantly adapting to shape their behavior for future interactions.Hierarchical AI AgentsHierarchical Agents are organized in tiers, with higher-level agents orchestrating lower-level counterparts. These levels, tailored to the system’s complexity, excel in diverse fields like robotics, manufacturing, and transportation, adept at coordinating multiple tasks and sub-tasks seamlessly.ConclusionIn a generation characterized by rapid AI advancement, the trajectory of AI Agents promises unparalleled autonomy, capable of making independent decisions with minimal human oversight. Their potential spans across diverse industries, revolutionizing customer service, predicting market demands, optimizing production lines, and beyond.The extensive applications of AI Agents hint at vast promise, yet ethical considerations remain most important. Responsible and beneficial utilization of these Agents is essential for enterprises venturing into this transformative journey.Market analysis shows that the 2024 year it’s the moment to embrace the formidable power of AI Agents at the enterprise’s level.AIArtificial IntelligenceAi AgentAGITech----1FollowWritten by Humans.ai377 Followers·Editor for humansdotaiHeart driven AIFollowHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://medium.com/humansdotai/an-introduction-to-ai-agents-e8c4afd2ee8f', 'title': 'An Introduction to AI Agents. Artificial Intelligence Agents are the… | by Humans.ai | humansdotai | Medium', 'description': 'Artificial Intelligence Agents are the digital newcomers revolutionizing our world. These agents, often called AI bots or virtual assistants, are intelligent systems programmed to perform tasks, make…', 'language': 'en'})]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.docstore.mget(doc_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f111ca83-3e56-4785-bac3-99948cd8df1b",
      "metadata": {
        "id": "f111ca83-3e56-4785-bac3-99948cd8df1b",
        "outputId": "6be2a2a7-6285-424b-93f9-9694879ec2ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='AI Agents are intelligent systems that can perform tasks, make decisions, and interact with their environment like humans do. They are powered by machine learning, natural language processing, and other advanced technologies, allowing them to learn from data, adapt to new information, and execute complex functions autonomously. AI Agents exist in various forms, such as chatbots providing customer service and robots used in healthcare and manufacturing. They are designed to understand, analyze, and respond to human input, constantly evolving to enhance their capabilities.\\n\\nAI Agents operate independently and can address customer queries, make fast decisions based on real-time information, and simplify business processes. They perceive their surroundings and execute actions through a range of tools, from rule-based systems to machine learning algorithms. AI Agents are the new face of intelligent automation and can handle vast streams of fresh data in uncertain landscapes.\\n\\nThe emergence of AI Agents represents a step towards Artificial General Intelligence (AGI), where machines will emulate human-like flexibility and proficiency across diverse domains. AI Agents work by initiating a journey toward a goal through engaging with core Language Learning Models, formulating a sequence of tasks, gathering relevant information, and iteratively refining their strategy until their objective is achieved.\\n\\nAI Agents transform businesses by infusing tasks with heightened performance, personalization, scalability, and cost-effectiveness. They can serve as guardians against errors, solvers of intricate puzzles, and creators of new fields of opportunities. In the economy, AI Agents have become indispensable across various business domains, revolutionizing service delivery, supply chains, and marketing strategies.\\n\\nDifferent types of AI Agents include Simple Reflex Agents, Model-Based Reflex Agents, Goal-based Agents, Utility-Based AI Agents, and Learning Agents. Hierarchical AI Agents are organized in tiers, with higher-level agents orchestrating lower-level counterparts. The potential of AI Agents spans across diverse industries, but responsible and beneficial utilization of these Agents is essential for enterprises. Market analysis suggests that 2024 is the year for enterprises to embrace the power of AI Agents.', metadata={'doc_id': '0fe1d412-c3c2-45c3-9637-57cc9948f0b4'})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What is agent\"\n",
        "sub_docs = vectorstore.similarity_search(query,k=1)\n",
        "sub_docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "729074f9-8bde-4c76-a7da-4cc0e50ed52d",
      "metadata": {
        "id": "729074f9-8bde-4c76-a7da-4cc0e50ed52d",
        "outputId": "550c951d-de4b-4977-9480-7f6476b9015a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Vasanth\\anaconda\\envs\\markdown-validation-crew\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'An Introduction to AI Agents. Artificial Intelligence Agents are the… | by Humans.ai | humansdotai | MediumOpen in appSign upSign inWriteSign upSign inAn Introduction to AI AgentsHumans.ai·FollowPublished inhumansdotai·7 min read·Dec 27, 2023--1ListenShareArtificial Intelligence Agents are the digital newcomers revolutionizing our world. These agents, often called AI bots or virtual assistants, are intelligent systems programmed to perform tasks, make decisions, and interact with their environme'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_docs = retriever.get_relevant_documents(query,n_results=1)\n",
        "retrieved_docs[0].page_content[0:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d09151ce-aea1-4574-84ab-a72f17bf59b4",
      "metadata": {
        "id": "d09151ce-aea1-4574-84ab-a72f17bf59b4"
      },
      "source": [
        "## Part 13: ColBERT\n",
        "\n",
        "RAGatouille makes it as simple to use ColBERT.\n",
        "\n",
        "ColBERT generates a contextually influenced vector for each token in the passages.\n",
        "\n",
        "ColBERT similarly generates vectors for each token in the query.\n",
        "\n",
        "Then, the score of each document is the sum of the maximum similarity of each query embedding to any of the document embeddings:\n",
        "\n",
        "See [here](https://hackernoon.com/how-colbert-helps-developers-overcome-the-limits-of-rag) and [here](https://python.langchain.com/docs/integrations/retrievers/ragatouille) and [here](https://til.simonwillison.net/llms/colbert-ragatouille)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "TxcmPHugWRY5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxcmPHugWRY5",
        "outputId": "e338f6d0-178a-412c-f5f7-ae2397d65179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ragatouille\n",
            "  Downloading ragatouille-0.0.8.post2-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m742.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colbert-ai==0.2.19 (from ragatouille)\n",
            "  Downloading colbert-ai-0.2.19.tar.gz (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting faiss-cpu<2.0.0,>=1.7.4 (from ragatouille)\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fast-pytorch-kmeans==0.2.0.1 (from ragatouille)\n",
            "  Downloading fast_pytorch_kmeans-0.2.0.1-py3-none-any.whl (8.8 kB)\n",
            "Collecting langchain<0.2.0,>=0.1.0 (from ragatouille)\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain_core<0.2.0,>=0.1.4 (from ragatouille)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index>=0.7 (from ragatouille)\n",
            "  Downloading llama_index-0.10.52-py3-none-any.whl (6.8 kB)\n",
            "Collecting onnx<2.0.0,>=1.15.0 (from ragatouille)\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers<3.0.0,>=2.2.2 (from ragatouille)\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: srsly==2.4.8 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (2.4.8)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.36.2 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (4.41.2)\n",
            "Collecting voyager<3.0.0,>=2.0.2 (from ragatouille)\n",
            "  Downloading voyager-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitarray (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m571.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (2.2.5)\n",
            "Collecting git-python (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
            "Collecting python-dotenv (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting ninja (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (4.66.4)\n",
            "Collecting ujson (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fast-pytorch-kmeans==0.2.0.1->ragatouille) (1.25.2)\n",
            "Collecting pynvml (from fast-pytorch-kmeans==0.2.0.1->ragatouille)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from srsly==2.4.8->ragatouille) (2.0.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu<2.0.0,>=1.7.4->ragatouille) (24.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain<0.2.0,>=0.1.0->ragatouille)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain<0.2.0,>=0.1.0->ragatouille)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.0->ragatouille)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain<0.2.0,>=0.1.0->ragatouille)\n",
            "  Downloading langsmith-0.1.83-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.8.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (8.4.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain_core<0.2.0,>=0.1.4->ragatouille)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging (from faiss-cpu<2.0.0,>=1.7.4->ragatouille)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_agent_openai-0.2.7-py3-none-any.whl (12 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
            "Collecting llama-index-core==0.10.52.post1 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_core-0.10.52.post1-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.2.3-py3-none-any.whl (9.2 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_llms_openai-0.1.25-py3-none-any.whl (11 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.7-py3-none-any.whl (5.9 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_readers_file-0.1.27-py3-none-any.whl (37 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (2023.6.0)\n",
            "Collecting httpx (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-cloud<0.0.7,>=0.0.6 (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_cloud-0.0.6-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (3.8.1)\n",
            "Collecting openai>=1.1.0 (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille)\n",
            "  Downloading openai-1.35.10-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (9.4.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (1.14.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx<2.0.0,>=1.15.0->ragatouille) (3.20.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (1.2.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (1.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->ragatouille)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->ragatouille)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->ragatouille)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->ragatouille)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->ragatouille)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->ragatouille)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->ragatouille)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->ragatouille)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->ragatouille)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13->ragatouille)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->ragatouille)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->ragatouille)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->ragatouille)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain_core<0.2.0,>=0.1.4->ragatouille)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.0->ragatouille)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_parse-0.4.5-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->ragatouille) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->ragatouille) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->ragatouille) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->ragatouille) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.0->ragatouille) (3.0.3)\n",
            "Collecting pyarrow>=15.0.0 (from datasets->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<3,>=2 (from langchain<0.2.0,>=0.1.0->ragatouille)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragatouille) (3.0.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragatouille) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragatouille) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->ragatouille) (2.1.5)\n",
            "Collecting gitpython (from git-python->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->ragatouille) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->ragatouille) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->ragatouille) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille) (2.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (1.7.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython->git-python->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (1.2.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.52.post1->llama-index>=0.7->ragatouille) (1.16.0)\n",
            "Building wheels for collected packages: colbert-ai\n",
            "  Building wheel for colbert-ai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colbert-ai: filename=colbert_ai-0.2.19-py3-none-any.whl size=114762 sha256=06be9090fbc1757cce38a8cc4924b0c441016b3d4ed465b77a02d37ac8c764fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/b9/63/d4fc276c73c42ef7fc1065a26cf87e5a1cf56ef6498cbfbe5d\n",
            "Successfully built colbert-ai\n",
            "Installing collected packages: striprtf, ninja, dirtyjson, bitarray, xxhash, voyager, ujson, smmap, requests, python-dotenv, pypdf, pynvml, pyarrow, packaging, orjson, onnx, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, jsonpointer, h11, dill, deprecated, typing-inspect, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, marshmallow, jsonpatch, httpcore, gitdb, faiss-cpu, nvidia-cusolver-cu12, langsmith, httpx, gitpython, dataclasses-json, openai, llama-cloud, langchain_core, git-python, datasets, sentence-transformers, llama-index-legacy, llama-index-core, langchain-text-splitters, langchain-community, fast-pytorch-kmeans, colbert-ai, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, langchain, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index, ragatouille\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitarray-2.9.2 colbert-ai-0.2.19 dataclasses-json-0.6.7 datasets-2.20.0 deprecated-1.2.14 dill-0.3.8 dirtyjson-1.0.8 faiss-cpu-1.8.0.post1 fast-pytorch-kmeans-0.2.0.1 git-python-1.0.3 gitdb-4.0.11 gitpython-3.1.43 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.1.20 langchain-community-0.0.38 langchain-text-splitters-0.0.2 langchain_core-0.1.52 langsmith-0.1.83 llama-cloud-0.0.6 llama-index-0.10.52 llama-index-agent-openai-0.2.7 llama-index-cli-0.1.12 llama-index-core-0.10.52.post1 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.2.3 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.25 llama-index-multi-modal-llms-openai-0.1.7 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.27 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.5 marshmallow-3.21.3 multiprocess-0.70.16 mypy-extensions-1.0.0 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 onnx-1.16.1 openai-1.35.10 orjson-3.10.6 packaging-23.2 pyarrow-16.1.0 pynvml-11.5.0 pypdf-4.2.0 python-dotenv-1.0.1 ragatouille-0.0.8.post2 requests-2.32.3 sentence-transformers-2.7.0 smmap-5.0.1 striprtf-0.0.26 tiktoken-0.7.0 typing-inspect-0.9.0 ujson-5.10.0 voyager-2.0.6 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "! pip install ragatouille"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "96deaaa9-5101-48a5-a93d-b8af0122430f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "f55f34da36fb4016a4a0494086c64641",
            "0b1d585d85824f888d39522ecb8a6f1f",
            "5c3f767339684ba894d39282b9edbbb7",
            "fad322935e6b4fbc8276abc2b85e1836",
            "4be9692e8be043c489f06a3abf27c64d",
            "4ba71b0eaff04537bc50bbca33aa4630",
            "7ac87a6e34984140a02a704c3e4ccf48",
            "1e9de6e09f82454381a7becdec58e8bf",
            "f347b06929df4fab84b1ab26338f4af6",
            "033667bb55444c3f9f629dd9ede1ec99",
            "d1773c06eeee4678953761276e51dcf1",
            "22cf57b760304a978df66d62eed18444",
            "ce12ae54e3424ac8835ab37b5d2538a4",
            "6c9de4615d71479ba94ee6c71de73ccb",
            "232ef42c0b9242a993254f861575d96f",
            "4606c9d425314c089779736ccd5e2450",
            "a6116981916849eebf946d98ae8691e0",
            "779f2ee7130e4d44b213dab4098672e2",
            "6b363d6326ea427389d849068c012232",
            "91d690a1ba354771bb838a2b0b18b79e",
            "5dd7c87d28b149cb940316e1349fee7e",
            "3978e89d4c3e4d79b2878d24cb9b9c04",
            "8f75d8d2a1ab4abc8b96fadf5f600dfb",
            "59123ebb89ad4cbdb1e720883ecda233",
            "20d54451d0174a8bb63aceef38882400",
            "4aec2d6583fb43e28748dac7ab2baab0",
            "ed62cedbc6024c61b76131f992e31af2",
            "ac6a1048895c4491ad1e68ae54e8f8e9",
            "5498b24697224a8eb9a4ecfde6ac4846",
            "841c4cb47e564e0ebb8095778d66c009",
            "252fa7545c1743f39d91cac5f3bfd98f",
            "f864969ec82b4317ba1e703c1c8d22c1",
            "c33ad59265ab41aba4c0e1cd7ee3070c",
            "6c255f2548db49dcae4895a12932ce00",
            "9844837561f6449485a618a5ddefabdc",
            "8661582dd02949ab9d922551b764c7b9",
            "ac4a22ba42da4369acd7a615f7e0b863",
            "d22750241cf04e32a11e7bc3a68cc2f4",
            "1b26567be0e547bf9653330ee3e9657a",
            "9dd945ef26ff46a481966617b067213b",
            "1c1157f83feb4b6cad7ef629a67f8e47",
            "9e56ab04c7b54dba911e615c64c8e8c8",
            "8bc753efac9445ddad71fca8a8ed3ae5",
            "8371a09564324bf5ade74da741e1afc6",
            "cc321c998b874fb79b1aedcdbf8eb532",
            "ee1cace3748c49999acec51380c87808",
            "ba5f73bc04a04df1bec10ec485127439",
            "faaa3db108f54b2b8cc68d26f814cb87",
            "4f08bd4dab974813aa757ec9c4aa963a",
            "a7e8f141bc434de6826b9d288710ae71",
            "cbcadf9a603b48acb63dae5b8ae018e3",
            "b75a53aa019d4fb3a1dd49fae3b71028",
            "b5e438a896a44bc58a805ccc5ab03dc4",
            "b9463b08a33e4bdeaa2f13f307c94a4e",
            "8d73beaf48cf49d39b0e0282883443a3",
            "1a13075d97244a8dad0d45bf48378d91",
            "088c9c3f25f7404cb36c641a85026683",
            "c793d1c900904cca8ffedf8aff00d9bc",
            "8623a516b70244efb6d672cd81b142a8",
            "37314ac1be75491fbcb9b1545dc3badc",
            "51cad1a6c9134a1c9b818222ac7138e7",
            "61af1a241ae54cf5ab71425047c34d3d",
            "a924f492ca3f4a5fbd48c57aee80c767",
            "119d9d2a3ae64961a46254e7a0a96e82",
            "c8dcb6be89934c408501870533049506",
            "605810870a4040deb1cd10ab0a057d5a",
            "a711db6e16974e498d689038a66344de",
            "da31decacd0a49fd8804be39dfab86f3",
            "3d3699228def403bbee1a5831c0ef5ca",
            "139fc4cf87d6413b852799dd74e9bab4",
            "46b90df0d418488f90c8543486a98e9e",
            "796ec3b798154839bfba5d5f26ba0eb2",
            "2c02a1c5ce2e44efbe2052dcc585b8ab",
            "ccf0334b4758450892167661416980ab",
            "6468201ba1814586a23be3ed3f78f190",
            "c16840916a2f45f1a11511542aff5b90",
            "b5f3df4f63c84fcf9222e95d5380a899"
          ]
        },
        "id": "96deaaa9-5101-48a5-a93d-b8af0122430f",
        "outputId": "bf1e8d2c-64cf-4918-d452-1f92fff705f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f55f34da36fb4016a4a0494086c64641",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "artifact.metadata:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22cf57b760304a978df66d62eed18444",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f75d8d2a1ab4abc8b96fadf5f600dfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c255f2548db49dcae4895a12932ce00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc321c998b874fb79b1aedcdbf8eb532",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a13075d97244a8dad0d45bf48378d91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a711db6e16974e498d689038a66344de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:05:37] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from ragatouille import RAGPretrainedModel\n",
        "RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "10b9bfc1-5f2b-4b9e-9934-9844e3b60646",
      "metadata": {
        "id": "10b9bfc1-5f2b-4b9e-9934-9844e3b60646"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def get_wikipedia_page(title: str):\n",
        "    \"\"\"\n",
        "    Retrieve the full text content of a Wikipedia page.\n",
        "\n",
        "    :param title: str - Title of the Wikipedia page.\n",
        "    :return: str - Full text content of the page as raw string.\n",
        "    \"\"\"\n",
        "    # Wikipedia API endpoint\n",
        "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    # Parameters for the API request\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"format\": \"json\",\n",
        "        \"titles\": title,\n",
        "        \"prop\": \"extracts\",\n",
        "        \"explaintext\": True,\n",
        "    }\n",
        "\n",
        "    # Custom User-Agent header to comply with Wikipedia's best practices\n",
        "    headers = {\"User-Agent\": \"RAGatouille_tutorial/0.0.1 (ben@clavie.eu)\"}\n",
        "\n",
        "    response = requests.get(URL, params=params, headers=headers)\n",
        "    data = response.json()\n",
        "\n",
        "    # Extracting page content\n",
        "    page = next(iter(data[\"query\"][\"pages\"].values()))\n",
        "    return page[\"extract\"] if \"extract\" in page else None\n",
        "\n",
        "full_document = get_wikipedia_page(\"Document_retrieval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a2317cc1-7406-4115-84c2-d0527a4ad22e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "a2317cc1-7406-4115-84c2-d0527a4ad22e",
        "outputId": "643d8793-e8f6-40f7-e380-0bfa4e5fa621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
            "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
            "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
            "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
            "--------------------\n",
            "\n",
            "\n",
            "[Jul 06, 00:07:28] #> Creating directory .ragatouille/colbert/indexes/Doc-1 \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:07:30] [0] \t\t #> Encoding 7 passages..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "100%|██████████| 1/1 [00:04<00:00,  4.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:07:35] [0] \t\t avg_doclen_est = 116.42857360839844 \t len(local_sample) = 7\n",
            "[Jul 06, 00:07:35] [0] \t\t Creating 256 partitions.\n",
            "[Jul 06, 00:07:35] [0] \t\t *Estimated* 815 embeddings.\n",
            "[Jul 06, 00:07:35] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/Doc-1/plan.json ..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: number of training points (775) is less than the minimum recommended (2560)\n",
            "used 6 iterations (0.0408s) to cluster 775 items into 256 clusters\n",
            "[0.036, 0.038, 0.038, 0.032, 0.034, 0.034, 0.033, 0.038, 0.029, 0.028, 0.032, 0.03, 0.029, 0.032, 0.036, 0.039, 0.03, 0.026, 0.029, 0.032, 0.029, 0.027, 0.03, 0.038, 0.039, 0.031, 0.031, 0.039, 0.03, 0.041, 0.034, 0.04, 0.03, 0.035, 0.03, 0.03, 0.034, 0.034, 0.027, 0.042, 0.027, 0.044, 0.035, 0.035, 0.034, 0.038, 0.027, 0.03, 0.025, 0.036, 0.028, 0.038, 0.028, 0.026, 0.033, 0.042, 0.04, 0.039, 0.038, 0.04, 0.033, 0.043, 0.029, 0.04, 0.04, 0.044, 0.032, 0.04, 0.033, 0.032, 0.029, 0.024, 0.041, 0.033, 0.041, 0.029, 0.038, 0.031, 0.041, 0.044, 0.037, 0.038, 0.033, 0.037, 0.038, 0.033, 0.039, 0.035, 0.033, 0.029, 0.031, 0.034, 0.032, 0.037, 0.037, 0.032, 0.036, 0.036, 0.032, 0.033, 0.029, 0.035, 0.035, 0.033, 0.036, 0.036, 0.028, 0.025, 0.035, 0.027, 0.042, 0.035, 0.034, 0.038, 0.039, 0.034, 0.031, 0.036, 0.035, 0.032, 0.03, 0.038, 0.026, 0.035, 0.028, 0.035, 0.037, 0.03]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:07:35] [0] \t\t #> Encoding 7 passages..\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:04<00:00,  4.51s/it]\n",
            "1it [00:04,  4.59s/it]\n",
            "100%|██████████| 1/1 [00:00<00:00, 798.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:07:39] #> Optimizing IVF to store map from centroids to list of pids..\n",
            "[Jul 06, 00:07:39] #> Building the emb2pid mapping..\n",
            "[Jul 06, 00:07:39] len(emb2pid) = 815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 256/256 [00:00<00:00, 15593.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:07:39] #> Saved optimized IVF to .ragatouille/colbert/indexes/Doc-1/ivf.pid.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done indexing!\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'.ragatouille/colbert/indexes/Doc-1'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RAG.index(\n",
        "    collection=[full_document],\n",
        "    index_name=\"Doc-1\",\n",
        "    max_document_length=180,\n",
        "    split_documents=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f929e4fd-2175-465d-bd88-664f67caa576",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f929e4fd-2175-465d-bd88-664f67caa576",
        "outputId": "db0ea720-6be3-4e26-b931-2a7d6a6fe063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading searcher for index Doc-1 for the first time... This may take a few seconds\n",
            "[Jul 06, 00:08:11] #> Loading codec...\n",
            "[Jul 06, 00:08:11] #> Loading IVF...\n",
            "[Jul 06, 00:08:11] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
            "[Jul 06, 00:08:48] #> Loading doclens...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 3279.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:08:48] #> Loading codes and residuals...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 130.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:08:48] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:09:20] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
            "Searcher loaded!\n",
            "\n",
            "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
            "#> Input: . What is an example for form based indexing?, \t\t True, \t\t None\n",
            "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2003, 2019, 2742, 2005, 2433, 2241, 5950, 2075, 1029,\n",
            "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
            "         103,  103,  103,  103,  103,  103,  103,  103])\n",
            "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'content': '== Variations ==\\nThere are two main classes of indexing schemata for document retrieval systems: form based (or word based), and content based indexing. The document classification scheme (or indexing algorithm) in use determines the nature of the document retrieval system.\\n\\n\\n=== Form based ===\\nForm based document retrieval addresses the exact syntactic properties of a text, comparable to substring matching in string searches. The text is generally unstructured and not necessarily in a natural language, the system could for example be used to process large sets of chemical representations in molecular biology. A suffix tree algorithm is an example for form based indexing.',\n",
              "  'score': 25.978090286254883,\n",
              "  'rank': 1,\n",
              "  'document_id': '83decb83-f58e-4d89-b9c1-51f09daadcfa',\n",
              "  'passage_id': 2},\n",
              " {'content': '== Example: PubMed ==\\nThe PubMed form interface features the \"related articles\" search which works through a comparison of words from the documents\\' title, abstract, and MeSH terms using a word-weighted algorithm.\\n\\n\\n== See also ==\\nCompound term processing\\nDocument classification\\nEnterprise search\\nEvaluation measures (information retrieval)\\nFull text search\\nInformation retrieval\\nLatent semantic indexing\\nSearch engine\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nFaloutsos, Christos; Christodoulakis, Stavros (1984). \"Signature files: An access method for documents and its analytical performance evaluation\". ACM Transactions on Information Systems. 2 (4): 267–288. doi:10.1145/2275.357411. S2CID 8120705.',\n",
              "  'score': 19.45407485961914,\n",
              "  'rank': 2,\n",
              "  'document_id': '83decb83-f58e-4d89-b9c1-51f09daadcfa',\n",
              "  'passage_id': 4},\n",
              " {'content': '=== Content based ===\\nThe content based approach exploits semantic connections between documents and parts thereof, and semantic connections between queries and documents. Most content based document retrieval systems use an inverted index algorithm.\\nA signature file is a technique that creates a quick and dirty filter, for example a Bloom filter, that will keep all the documents that match to the query and hopefully a few ones that do not. The way this is done is by creating for each file a signature, typically a hash coded version. One method is superimposed coding. A post-processing step is done to discard the false alarms. Since in most cases this structure is inferior to inverted files in terms of speed, size and functionality, it is not used widely. However, with proper parameters it can beat the inverted files in certain environments.',\n",
              "  'score': 19.071989059448242,\n",
              "  'rank': 3,\n",
              "  'document_id': '83decb83-f58e-4d89-b9c1-51f09daadcfa',\n",
              "  'passage_id': 3}]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = RAG.search(query=\"What is an example for form based indexing?\", k=3)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ca1cbbc7-bd6e-488d-9419-740a62eb097a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca1cbbc7-bd6e-488d-9419-740a62eb097a",
        "outputId": "97fb2c8b-e3fb-49c8-ff8b-f0ed8ae43f94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(page_content='== Variations ==\\nThere are two main classes of indexing schemata for document retrieval systems: form based (or word based), and content based indexing. The document classification scheme (or indexing algorithm) in use determines the nature of the document retrieval system.\\n\\n\\n=== Form based ===\\nForm based document retrieval addresses the exact syntactic properties of a text, comparable to substring matching in string searches. The text is generally unstructured and not necessarily in a natural language, the system could for example be used to process large sets of chemical representations in molecular biology. A suffix tree algorithm is an example for form based indexing.'),\n",
              " Document(page_content='== Example: PubMed ==\\nThe PubMed form interface features the \"related articles\" search which works through a comparison of words from the documents\\' title, abstract, and MeSH terms using a word-weighted algorithm.\\n\\n\\n== See also ==\\nCompound term processing\\nDocument classification\\nEnterprise search\\nEvaluation measures (information retrieval)\\nFull text search\\nInformation retrieval\\nLatent semantic indexing\\nSearch engine\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nFaloutsos, Christos; Christodoulakis, Stavros (1984). \"Signature files: An access method for documents and its analytical performance evaluation\". ACM Transactions on Information Systems. 2 (4): 267–288. doi:10.1145/2275.357411. S2CID 8120705.'),\n",
              " Document(page_content='=== Content based ===\\nThe content based approach exploits semantic connections between documents and parts thereof, and semantic connections between queries and documents. Most content based document retrieval systems use an inverted index algorithm.\\nA signature file is a technique that creates a quick and dirty filter, for example a Bloom filter, that will keep all the documents that match to the query and hopefully a few ones that do not. The way this is done is by creating for each file a signature, typically a hash coded version. One method is superimposed coding. A post-processing step is done to discard the false alarms. Since in most cases this structure is inferior to inverted files in terms of speed, size and functionality, it is not used widely. However, with proper parameters it can beat the inverted files in certain environments.')]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever = RAG.as_langchain_retriever(k=3)\n",
        "retriever.invoke(\"What is an example for form based indexing?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zn5ZK6ycXxqX",
      "metadata": {
        "id": "zn5ZK6ycXxqX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "033667bb55444c3f9f629dd9ede1ec99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088c9c3f25f7404cb36c641a85026683": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51cad1a6c9134a1c9b818222ac7138e7",
            "placeholder": "​",
            "style": "IPY_MODEL_61af1a241ae54cf5ab71425047c34d3d",
            "value": "tokenizer.json: 100%"
          }
        },
        "0b1d585d85824f888d39522ecb8a6f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ba71b0eaff04537bc50bbca33aa4630",
            "placeholder": "​",
            "style": "IPY_MODEL_7ac87a6e34984140a02a704c3e4ccf48",
            "value": "artifact.metadata: 100%"
          }
        },
        "119d9d2a3ae64961a46254e7a0a96e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "139fc4cf87d6413b852799dd74e9bab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16840916a2f45f1a11511542aff5b90",
            "placeholder": "​",
            "style": "IPY_MODEL_b5f3df4f63c84fcf9222e95d5380a899",
            "value": " 112/112 [00:00&lt;00:00, 2.63kB/s]"
          }
        },
        "1a13075d97244a8dad0d45bf48378d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_088c9c3f25f7404cb36c641a85026683",
              "IPY_MODEL_c793d1c900904cca8ffedf8aff00d9bc",
              "IPY_MODEL_8623a516b70244efb6d672cd81b142a8"
            ],
            "layout": "IPY_MODEL_37314ac1be75491fbcb9b1545dc3badc"
          }
        },
        "1b26567be0e547bf9653330ee3e9657a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c1157f83feb4b6cad7ef629a67f8e47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e9de6e09f82454381a7becdec58e8bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20d54451d0174a8bb63aceef38882400": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_841c4cb47e564e0ebb8095778d66c009",
            "max": 438349816,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_252fa7545c1743f39d91cac5f3bfd98f",
            "value": 438349816
          }
        },
        "22cf57b760304a978df66d62eed18444": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce12ae54e3424ac8835ab37b5d2538a4",
              "IPY_MODEL_6c9de4615d71479ba94ee6c71de73ccb",
              "IPY_MODEL_232ef42c0b9242a993254f861575d96f"
            ],
            "layout": "IPY_MODEL_4606c9d425314c089779736ccd5e2450"
          }
        },
        "232ef42c0b9242a993254f861575d96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dd7c87d28b149cb940316e1349fee7e",
            "placeholder": "​",
            "style": "IPY_MODEL_3978e89d4c3e4d79b2878d24cb9b9c04",
            "value": " 743/743 [00:00&lt;00:00, 31.2kB/s]"
          }
        },
        "252fa7545c1743f39d91cac5f3bfd98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c02a1c5ce2e44efbe2052dcc585b8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37314ac1be75491fbcb9b1545dc3badc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3978e89d4c3e4d79b2878d24cb9b9c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d3699228def403bbee1a5831c0ef5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccf0334b4758450892167661416980ab",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6468201ba1814586a23be3ed3f78f190",
            "value": 112
          }
        },
        "4606c9d425314c089779736ccd5e2450": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46b90df0d418488f90c8543486a98e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aec2d6583fb43e28748dac7ab2baab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f864969ec82b4317ba1e703c1c8d22c1",
            "placeholder": "​",
            "style": "IPY_MODEL_c33ad59265ab41aba4c0e1cd7ee3070c",
            "value": " 438M/438M [00:03&lt;00:00, 142MB/s]"
          }
        },
        "4ba71b0eaff04537bc50bbca33aa4630": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be9692e8be043c489f06a3abf27c64d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f08bd4dab974813aa757ec9c4aa963a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51cad1a6c9134a1c9b818222ac7138e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5498b24697224a8eb9a4ecfde6ac4846": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59123ebb89ad4cbdb1e720883ecda233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac6a1048895c4491ad1e68ae54e8f8e9",
            "placeholder": "​",
            "style": "IPY_MODEL_5498b24697224a8eb9a4ecfde6ac4846",
            "value": "model.safetensors: 100%"
          }
        },
        "5c3f767339684ba894d39282b9edbbb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e9de6e09f82454381a7becdec58e8bf",
            "max": 1633,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f347b06929df4fab84b1ab26338f4af6",
            "value": 1633
          }
        },
        "5dd7c87d28b149cb940316e1349fee7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605810870a4040deb1cd10ab0a057d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61af1a241ae54cf5ab71425047c34d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6468201ba1814586a23be3ed3f78f190": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b363d6326ea427389d849068c012232": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c255f2548db49dcae4895a12932ce00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9844837561f6449485a618a5ddefabdc",
              "IPY_MODEL_8661582dd02949ab9d922551b764c7b9",
              "IPY_MODEL_ac4a22ba42da4369acd7a615f7e0b863"
            ],
            "layout": "IPY_MODEL_d22750241cf04e32a11e7bc3a68cc2f4"
          }
        },
        "6c9de4615d71479ba94ee6c71de73ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b363d6326ea427389d849068c012232",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91d690a1ba354771bb838a2b0b18b79e",
            "value": 743
          }
        },
        "779f2ee7130e4d44b213dab4098672e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "796ec3b798154839bfba5d5f26ba0eb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac87a6e34984140a02a704c3e4ccf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8371a09564324bf5ade74da741e1afc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "841c4cb47e564e0ebb8095778d66c009": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8623a516b70244efb6d672cd81b142a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8dcb6be89934c408501870533049506",
            "placeholder": "​",
            "style": "IPY_MODEL_605810870a4040deb1cd10ab0a057d5a",
            "value": " 466k/466k [00:00&lt;00:00, 5.60MB/s]"
          }
        },
        "8661582dd02949ab9d922551b764c7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c1157f83feb4b6cad7ef629a67f8e47",
            "max": 405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e56ab04c7b54dba911e615c64c8e8c8",
            "value": 405
          }
        },
        "8bc753efac9445ddad71fca8a8ed3ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d73beaf48cf49d39b0e0282883443a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f75d8d2a1ab4abc8b96fadf5f600dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59123ebb89ad4cbdb1e720883ecda233",
              "IPY_MODEL_20d54451d0174a8bb63aceef38882400",
              "IPY_MODEL_4aec2d6583fb43e28748dac7ab2baab0"
            ],
            "layout": "IPY_MODEL_ed62cedbc6024c61b76131f992e31af2"
          }
        },
        "91d690a1ba354771bb838a2b0b18b79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9844837561f6449485a618a5ddefabdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b26567be0e547bf9653330ee3e9657a",
            "placeholder": "​",
            "style": "IPY_MODEL_9dd945ef26ff46a481966617b067213b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9dd945ef26ff46a481966617b067213b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e56ab04c7b54dba911e615c64c8e8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6116981916849eebf946d98ae8691e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a711db6e16974e498d689038a66344de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da31decacd0a49fd8804be39dfab86f3",
              "IPY_MODEL_3d3699228def403bbee1a5831c0ef5ca",
              "IPY_MODEL_139fc4cf87d6413b852799dd74e9bab4"
            ],
            "layout": "IPY_MODEL_46b90df0d418488f90c8543486a98e9e"
          }
        },
        "a7e8f141bc434de6826b9d288710ae71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a924f492ca3f4a5fbd48c57aee80c767": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac4a22ba42da4369acd7a615f7e0b863": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bc753efac9445ddad71fca8a8ed3ae5",
            "placeholder": "​",
            "style": "IPY_MODEL_8371a09564324bf5ade74da741e1afc6",
            "value": " 405/405 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "ac6a1048895c4491ad1e68ae54e8f8e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5e438a896a44bc58a805ccc5ab03dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5f3df4f63c84fcf9222e95d5380a899": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b75a53aa019d4fb3a1dd49fae3b71028": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9463b08a33e4bdeaa2f13f307c94a4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba5f73bc04a04df1bec10ec485127439": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b75a53aa019d4fb3a1dd49fae3b71028",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5e438a896a44bc58a805ccc5ab03dc4",
            "value": 231508
          }
        },
        "c16840916a2f45f1a11511542aff5b90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c33ad59265ab41aba4c0e1cd7ee3070c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c793d1c900904cca8ffedf8aff00d9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a924f492ca3f4a5fbd48c57aee80c767",
            "max": 466081,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_119d9d2a3ae64961a46254e7a0a96e82",
            "value": 466081
          }
        },
        "c8dcb6be89934c408501870533049506": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbcadf9a603b48acb63dae5b8ae018e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc321c998b874fb79b1aedcdbf8eb532": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee1cace3748c49999acec51380c87808",
              "IPY_MODEL_ba5f73bc04a04df1bec10ec485127439",
              "IPY_MODEL_faaa3db108f54b2b8cc68d26f814cb87"
            ],
            "layout": "IPY_MODEL_4f08bd4dab974813aa757ec9c4aa963a"
          }
        },
        "ccf0334b4758450892167661416980ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce12ae54e3424ac8835ab37b5d2538a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6116981916849eebf946d98ae8691e0",
            "placeholder": "​",
            "style": "IPY_MODEL_779f2ee7130e4d44b213dab4098672e2",
            "value": "config.json: 100%"
          }
        },
        "d1773c06eeee4678953761276e51dcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d22750241cf04e32a11e7bc3a68cc2f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da31decacd0a49fd8804be39dfab86f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_796ec3b798154839bfba5d5f26ba0eb2",
            "placeholder": "​",
            "style": "IPY_MODEL_2c02a1c5ce2e44efbe2052dcc585b8ab",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "ed62cedbc6024c61b76131f992e31af2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1cace3748c49999acec51380c87808": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e8f141bc434de6826b9d288710ae71",
            "placeholder": "​",
            "style": "IPY_MODEL_cbcadf9a603b48acb63dae5b8ae018e3",
            "value": "vocab.txt: 100%"
          }
        },
        "f347b06929df4fab84b1ab26338f4af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f55f34da36fb4016a4a0494086c64641": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b1d585d85824f888d39522ecb8a6f1f",
              "IPY_MODEL_5c3f767339684ba894d39282b9edbbb7",
              "IPY_MODEL_fad322935e6b4fbc8276abc2b85e1836"
            ],
            "layout": "IPY_MODEL_4be9692e8be043c489f06a3abf27c64d"
          }
        },
        "f864969ec82b4317ba1e703c1c8d22c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faaa3db108f54b2b8cc68d26f814cb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9463b08a33e4bdeaa2f13f307c94a4e",
            "placeholder": "​",
            "style": "IPY_MODEL_8d73beaf48cf49d39b0e0282883443a3",
            "value": " 232k/232k [00:00&lt;00:00, 2.99MB/s]"
          }
        },
        "fad322935e6b4fbc8276abc2b85e1836": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_033667bb55444c3f9f629dd9ede1ec99",
            "placeholder": "​",
            "style": "IPY_MODEL_d1773c06eeee4678953761276e51dcf1",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 34.5kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
